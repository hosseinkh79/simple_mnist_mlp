{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# ROOT_DATA_PATH = 'E:\\\\Programming\\\\Per\\\\Python\\\\Uni_Projects\\\\Neural_Networks\\\\mnist_project\\\\data'\n",
    "\n",
    "# # Define a transform to normalize the data\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),  # Converts PIL Image or numpy.ndarray to a torch.FloatTensor\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "# # Download and load the training set\n",
    "# batch_size = 64\n",
    "\n",
    "# train_dataset = datasets.MNIST(root=ROOT_DATA_PATH, train=True, transform=transform, download=True)\n",
    "# train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Similarly, you can download and load the test set\n",
    "# test_dataset = datasets.MNIST(root=ROOT_DATA_PATH, train=False, transform=transform, download=True)\n",
    "# test_dataloader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(train_dataset), train_dataset.classes\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# images, labels = next(iter(train_dataloader))\n",
    "# image = images[0].view(1, 28, 28)\n",
    "# label = labels[0].item()\n",
    "# # print(label)\n",
    "# image = image.permute(1, 2, 0)\n",
    "# # image = image * 0.5 + 0.5\n",
    "# # plt.imshow(image);\n",
    "# # plt.title(f'label : '+str(label));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, list_hidden_features_size):\n",
    "        super().__init__()\n",
    "        # self.num_hidden_layer = num_hidden_layer\n",
    "\n",
    "        self.input_layer = nn.Linear(in_features, list_hidden_features_size[0])\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList(\n",
    "            [nn.Linear(list_hidden_features_size[i], list_hidden_features_size[i+1]) for i in range(len(list_hidden_features_size)-1)]\n",
    "        )\n",
    "\n",
    "        self.out_layer = nn.Linear(list_hidden_features_size[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x)) \n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "\n",
    "        x = self.out_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# X, y = next(iter(train_dataloader))\n",
    "# print(X.shape)\n",
    "\n",
    "# in_feat = X.shape[-1] * X.shape[-1]\n",
    "# hiddens = [32, 20, 15]\n",
    "# model = MLP(in_features=in_feat, num_classes=10, list_hidden_features_size=hiddens)\n",
    "\n",
    "\n",
    "# print(X.shape)\n",
    "# X = X.view(batch_size, -1)\n",
    "# print(X.shape)\n",
    "\n",
    "# out = model(X)\n",
    "# out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.onnx\n",
    "\n",
    "# # Specify input size\n",
    "# model = model.to('cpu')\n",
    "# dummy_input = image.to('cpu')\n",
    "\n",
    "# # Export the model to ONNX\n",
    "# onnx_path = 'E:\\\\dynamic_linear_model.onnx'\n",
    "# torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test \n",
    "def one_step_train(model, train_dataloader, loss_fn, optimizer, device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X.view(X.size(0), -1))\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += ((y_pred_class == y).sum().item())/len(y_pred)\n",
    "\n",
    "    train_loss = train_loss/len(train_dataloader)\n",
    "    train_acc = train_acc/len(train_dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def one_step_test(model, test_dataloader, loss_fn, device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model(X.view(X.size(0), -1))\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            test_acc += ((y_pred_class == y).sum().item())/len(y_pred)\n",
    "\n",
    "        test_loss = test_loss/len(test_dataloader)\n",
    "        test_acc = test_acc/len(test_dataloader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "from torchinfo import summary\n",
    "\n",
    "from going_modular.model import MLP\n",
    "from going_modular.utils import plot_loss_curves\n",
    "from going_modular import engine\n",
    "\n",
    "from going_modular.data_setup import train_dataset, train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hiddens = [64, 32, 16]\n",
    "model = MLP(in_features=784, num_classes=10, list_hidden_features_size=hiddens)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, input_size=(64, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# def train(model,\n",
    "#           train_dataloader,\n",
    "#           test_dataloader,\n",
    "#           loss_fn,\n",
    "#           optimizer,\n",
    "#           device,\n",
    "#           epochs):\n",
    "    \n",
    "#     results = {\n",
    "#             'train_loss':[],\n",
    "#             'train_acc':[],\n",
    "#             'test_loss':[],\n",
    "#             'test_acc':[]\n",
    "#         }\n",
    "    \n",
    "#     for epoch in tqdm(range(epochs)):\n",
    "\n",
    "#         train_loss, train_acc = one_step_train(model,\n",
    "#                                                 train_dataloader,\n",
    "#                                                 loss_fn, optimizer,\n",
    "#                                                 device)\n",
    "\n",
    "#         test_loss, test_acc = one_step_test(model,\n",
    "#                                             test_dataloader,\n",
    "#                                             loss_fn,\n",
    "#                                             device)\n",
    "\n",
    "#         results['train_loss'].append(train_loss)\n",
    "#         results['train_acc'].append(train_acc)\n",
    "#         results['test_loss'].append(test_loss)\n",
    "#         results['test_acc'].append(test_acc)\n",
    "\n",
    "#         print(\n",
    "#           f\"Epoch: {epoch+1} | \"\n",
    "#           f\"train_loss: {train_loss:.4f} | \"\n",
    "#           f\"train_acc: {train_acc:.4f} | \"\n",
    "#           f\"test_loss: {test_loss:.4f} | \"\n",
    "#           f\"test_acc: {test_acc:.4f}\"\n",
    "#         )\n",
    "        \n",
    "#     return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:MLP (num_hyden_layers:1)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hiddens = [128, 128]\n",
    "model = MLP(in_features=784, num_classes=10, list_hidden_features_size=hiddens)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.00001)\n",
    "\n",
    "# results = engine.train(model=model,\n",
    "#       train_dataloader=train_dataloader,\n",
    "#       test_dataloader=test_dataloader,\n",
    "#       loss_fn=loss_fn,\n",
    "#       optimizer=optimizer,\n",
    "#       device=device,\n",
    "#       epochs=1)\n",
    "\n",
    "# plot_loss_curves(results=results)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# Specify input size\n",
    "model = model.to('cpu')\n",
    "dummy_input = torch.rand(64, 784, dtype=torch.float).to('cpu')\n",
    "\n",
    "# Export the model to ONNX\n",
    "onnx_path = 'E:\\\\linear_model.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curves(results):\n",
    "\n",
    "#     loss = results[\"train_loss\"]\n",
    "#     test_loss = results[\"test_loss\"]\n",
    "\n",
    "#     accuracy = results[\"train_acc\"]\n",
    "#     test_accuracy = results[\"test_acc\"]\n",
    "\n",
    "#     epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "\n",
    "#     # Plot loss\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs, loss, label=\"train_loss\")\n",
    "#     plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "#     plt.title(\"Loss\")\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Plot accuracy\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "#     plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "#     plt.title(\"Accuracy\")\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_curves(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_dataset.targets\n",
    "# dataset_indices = list(range(len(train_dataset)))\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# batch_size = 64\n",
    "\n",
    "# kfold_tests_results = []\n",
    "# for fold, (train_index, val_index) in enumerate(skf.split(dataset_indices, y)):\n",
    "    \n",
    "#     train_dataset_fold = Subset(train_dataset, train_index)\n",
    "#     train_loader = DataLoader(train_dataset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#     valid_dataset_fold = Subset(train_dataset, val_index)\n",
    "#     valid_loader = DataLoader(valid_dataset_fold, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "#     results_each_fold = engine.train(model=model, \n",
    "#                                         train_dataloader=train_loader,\n",
    "#                                         test_dataloader=valid_loader,\n",
    "#                                         loss_fn=loss_fn, \n",
    "#                                         optimizer=optimizer, \n",
    "#                                         device=device,\n",
    "#                                         epochs=1)\n",
    "#     #return last test_acc \n",
    "#     last_test_acc = kfold_tests_results.append(results_each_fold['test_acc'][-1]) \n",
    "\n",
    "# print(f'test_accs is :{kfold_tests_results}')\n",
    "# print(f'test_acc mean for our model is :{sum(kfold_tests_results)/len(kfold_tests_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
